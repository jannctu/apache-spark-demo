{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "appName = \"Data Preprocessing\"\n",
    "spark = SparkSession.builder.appName(appName).config(\"spark.some.config.option\",\"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightSchema = StructType([\n",
    "  StructField(\"DayofMonth\", IntegerType(), False),\n",
    "  StructField(\"DayOfWeek\", IntegerType(), False),\n",
    "  StructField(\"Carrier\", StringType(), False),\n",
    "  StructField(\"OriginAirportID\", IntegerType(), False),\n",
    "  StructField(\"DestAirportID\", IntegerType(), False),\n",
    "  StructField(\"DepDelay\", IntegerType(), False),\n",
    "  StructField(\"ArrDelay\", IntegerType(), False),\n",
    "])\n",
    "\n",
    "flights = spark.read.csv('dataset/raw-flight-data.csv', \n",
    "                         schema=flightSchema, header=True)\n",
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+\n",
      "|airport_id|       city|state|                name|\n",
      "+----------+-----------+-----+--------------------+\n",
      "|     10165|Adak Island|   AK|                Adak|\n",
      "|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n",
      "+----------+-----------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airportSchema = StructType([\n",
    "  StructField(\"airport_id\", IntegerType(), False),\n",
    "  StructField(\"city\", StringType(), False),\n",
    "  StructField(\"state\", StringType(), False),\n",
    "  StructField(\"name\", StringType(), False),\n",
    "])\n",
    "\n",
    "airports = spark.read.csv('dataset/airports.csv', header=True, \n",
    "                          schema=airportSchema)\n",
    "airports.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          city|count|\n",
      "+--------------+-----+\n",
      "|       Phoenix|90281|\n",
      "|         Omaha|13537|\n",
      "|Raleigh/Durham|28436|\n",
      "|     Anchorage| 7777|\n",
      "|        Dallas|19503|\n",
      "+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsByOrigin = flights.join(airports,\n",
    "                               flights.OriginAirportID == \n",
    "                               airports.airport_id).groupBy(\"city\").count()\n",
    "flightsByOrigin.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of original data rows:  2719418\n",
      "number of data rows after deleting duplicated data:  2696983\n",
      "number of duplicated data:  22435\n"
     ]
    }
   ],
   "source": [
    "#count the number of original data rows\n",
    "n1 = flights.count()\n",
    "print(\"number of original data rows: \", n1)\n",
    "#count the number of data rows after deleting duplicated data\n",
    "n2 = flights.dropDuplicates().count()\n",
    "print(\"number of data rows after deleting duplicated data: \", n2)\n",
    "n3 = n1 - n2\n",
    "print(\"number of duplicated data: \", n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "| Jan| 27|   168|\n",
      "| Jan| 15|   165|\n",
      "| Jan| 27|   168|\n",
      "+----+---+------+\n",
      "\n",
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "| Jan| 27|   168|\n",
      "| Jan| 15|   165|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(\"Jan\",27, 168), \n",
    "                            (\"Jan\",15, 165), \n",
    "                            (\"Jan\",27, 168)], \n",
    "                           [\"name\",\"age\",\"height\"])\n",
    "df.show()\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|height|\n",
      "+----+---+------+\n",
      "| Jan| 27|   168|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.dropDuplicates(['name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing value rows:  46233\n"
     ]
    }
   ],
   "source": [
    "flightsNoMissingValue = flights.dropDuplicates().dropna(\n",
    "    how=\"any\", subset=[\"ArrDelay\", \"DepDelay\"])# use how=\"all\" for all column missing data\n",
    "numberOfMissingValueAny = n1 - flightsNoMissingValue.count()\n",
    "print(\"number of missing value rows: \", numberOfMissingValueAny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean ArrDelay:  6.63768791455498\n",
      "mean DepDelay:  10.53686662649788\n",
      "+----------------+\n",
      "|   avg(ArrDelay)|\n",
      "+----------------+\n",
      "|6.63768791455498|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#take mean value\n",
    "meanArrDelay = flights.groupBy().avg(\"ArrDelay\").take(1)[0][0]\n",
    "print(\"mean ArrDelay: \", meanArrDelay)\n",
    "meanDepDelay = flights.groupBy().avg(\"DepDelay\").take(1)[0][0]\n",
    "print(\"mean DepDelay: \", meanDepDelay)\n",
    "#drop duplicated data and fill missing data with mean value\n",
    "flightsCleanData=flights.fillna(\n",
    "    {'ArrDelay': meanArrDelay, 'DepDelay': meanDepDelay})\n",
    "#just for experiment\n",
    "flights.groupBy().avg(\"ArrDelay\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|          DepDelay|         ArrDelay|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|           2719418|          2719418|\n",
      "|   mean|10.531448640848888|6.630879842672218|\n",
      "| stddev| 35.91695039008106|38.44200618946955|\n",
      "|    min|               -63|              -94|\n",
      "|    max|              1863|             1845|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsCleanData.describe('DepDelay','ArrDelay').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between departure delay and arrival delay:  0.9393538215572607\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correlation = flightsCleanData.corr('DepDelay', 'ArrDelay')\n",
    "print(\"correlation between departure delay and arrival delay: \", \n",
    "      correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
